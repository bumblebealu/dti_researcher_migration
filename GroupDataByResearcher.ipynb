{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1cbda93",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7aa5dd",
   "metadata": {},
   "source": [
    "This notebook will take in a dataframe with paths, countries, country latitudes, and country longitudes and output a dataframe with the following columns: addresspath(unique); country_list(all unique countries in \"order\"), latlist(all latitudes corresponding to unique countries), longlist(all longitudes...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5e806",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b57112a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17034ac3",
   "metadata": {},
   "source": [
    "# Loading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f392d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@path</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>aff</th>\n",
       "      <th>block</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country</th>\n",
       "      <th>country_latitude</th>\n",
       "      <th>country_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/0000-0003-1178-1001</td>\n",
       "      <td>Class of ghost-free non-Abelian gauge theories</td>\n",
       "      <td>We discuss a class of non-Abelian gauge theori...</td>\n",
       "      <td>Frenkel, Josif</td>\n",
       "      <td>Instituto de Fisica, Universidade de São Paulo...</td>\n",
       "      <td>j.frenkel</td>\n",
       "      <td>-23.559998</td>\n",
       "      <td>-46.735252</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>-10.806774</td>\n",
       "      <td>-53.054340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/0000-0001-5974-7043</td>\n",
       "      <td>Weak nonleptonic decays of charmed hadrons in ...</td>\n",
       "      <td>We analyze the two-body weak nonleptonic decay...</td>\n",
       "      <td>Branco, G.</td>\n",
       "      <td>Department of Physics, The City College of the...</td>\n",
       "      <td>g.branco</td>\n",
       "      <td>40.820047</td>\n",
       "      <td>-73.949272</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>45.705628</td>\n",
       "      <td>-112.599436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/0000-0003-2257-3080</td>\n",
       "      <td>Target asymmetry in inclusive photoproduction ...</td>\n",
       "      <td>We study the target asymmetry in inclusive pio...</td>\n",
       "      <td>Craigie, N. S.</td>\n",
       "      <td>CERN, Geneva, Switzerland</td>\n",
       "      <td>n.craigie</td>\n",
       "      <td>46.204391</td>\n",
       "      <td>6.143158</td>\n",
       "      <td>France</td>\n",
       "      <td>42.460704</td>\n",
       "      <td>-2.876697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/0000-0003-2257-3080</td>\n",
       "      <td>A space-time description of quarks and hadrons</td>\n",
       "      <td>A more concrete formulation of the previously ...</td>\n",
       "      <td>Craigie, N. S.</td>\n",
       "      <td>CERN, Geneva, Switzerland</td>\n",
       "      <td>n.craigie</td>\n",
       "      <td>46.204391</td>\n",
       "      <td>6.143158</td>\n",
       "      <td>France</td>\n",
       "      <td>42.460704</td>\n",
       "      <td>-2.876697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/0000-0001-9638-3082</td>\n",
       "      <td>Observation of spatial and temporal variations...</td>\n",
       "      <td>Observations of X-ray bright points (XBP) over...</td>\n",
       "      <td>Golub, L.</td>\n",
       "      <td>American Science and Engineering, Inc., Cambri...</td>\n",
       "      <td>l.golub</td>\n",
       "      <td>42.524182</td>\n",
       "      <td>-71.254940</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>45.705628</td>\n",
       "      <td>-112.599436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  @path                                              title  \\\n",
       "0  /0000-0003-1178-1001     Class of ghost-free non-Abelian gauge theories   \n",
       "1  /0000-0001-5974-7043  Weak nonleptonic decays of charmed hadrons in ...   \n",
       "2  /0000-0003-2257-3080  Target asymmetry in inclusive photoproduction ...   \n",
       "3  /0000-0003-2257-3080     A space-time description of quarks and hadrons   \n",
       "4  /0000-0001-9638-3082  Observation of spatial and temporal variations...   \n",
       "\n",
       "                                            abstract          author  \\\n",
       "0  We discuss a class of non-Abelian gauge theori...  Frenkel, Josif   \n",
       "1  We analyze the two-body weak nonleptonic decay...      Branco, G.   \n",
       "2  We study the target asymmetry in inclusive pio...  Craigie, N. S.   \n",
       "3  A more concrete formulation of the previously ...  Craigie, N. S.   \n",
       "4  Observations of X-ray bright points (XBP) over...       Golub, L.   \n",
       "\n",
       "                                                 aff      block   latitude  \\\n",
       "0  Instituto de Fisica, Universidade de São Paulo...  j.frenkel -23.559998   \n",
       "1  Department of Physics, The City College of the...   g.branco  40.820047   \n",
       "2                          CERN, Geneva, Switzerland  n.craigie  46.204391   \n",
       "3                          CERN, Geneva, Switzerland  n.craigie  46.204391   \n",
       "4  American Science and Engineering, Inc., Cambri...    l.golub  42.524182   \n",
       "\n",
       "   longitude                   country  country_latitude  country_longitude  \n",
       "0 -46.735252                    Brazil        -10.806774         -53.054340  \n",
       "1 -73.949272  United States of America         45.705628        -112.599436  \n",
       "2   6.143158                    France         42.460704          -2.876697  \n",
       "3   6.143158                    France         42.460704          -2.876697  \n",
       "4 -71.254940  United States of America         45.705628        -112.599436  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_hdf(\"migration_dataset_with_countries_dropNA.h5\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd56b4",
   "metadata": {},
   "source": [
    "# Create new Grouped Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2e360",
   "metadata": {},
   "source": [
    "We will check how many unique paths there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72bb6071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Paths: 153035\n",
      "Unique Paths: 28152\n"
     ]
    }
   ],
   "source": [
    "total_paths = df[\"@path\"].size\n",
    "unique_paths = df[\"@path\"].unique().size\n",
    "print(f\"Total Paths: {total_paths}\")\n",
    "print(f\"Unique Paths: {unique_paths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718e6cf",
   "metadata": {},
   "source": [
    "Check how many unique authors there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8116bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Authors: 153035\n",
      "Unique Authors: 40123\n"
     ]
    }
   ],
   "source": [
    "total_auths = df[\"author\"].size\n",
    "unique_auths = df[\"author\"].unique().size\n",
    "print(f\"Total Authors: {total_auths}\")\n",
    "print(f\"Unique Authors: {unique_auths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d04d91",
   "metadata": {},
   "source": [
    "Unsurprisingly, there are many more \"unique\" authors than unique paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79646dd0",
   "metadata": {},
   "source": [
    "### Now lets use the groupby function and print an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e867f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group '@path'=/0000-0001-5008-8619:\n",
      "\n",
      "29268     Italy\n",
      "29269     Italy\n",
      "29270     Italy\n",
      "43147     Italy\n",
      "52301     Italy\n",
      "75814     Italy\n",
      "107199    Italy\n",
      "107200    Italy\n",
      "126589    Italy\n",
      "126590    Italy\n",
      "Name: country, dtype: object\n",
      "\n",
      "Group '@path'=/0000-0001-5009-0727:\n",
      "\n",
      "24647    Denmark\n",
      "29864    Denmark\n",
      "Name: country, dtype: object\n",
      "\n",
      "Group '@path'=/0000-0001-5009-2271:\n",
      "\n",
      "119522    Italy\n",
      "Name: country, dtype: object\n",
      "\n",
      "Group '@path'=/0000-0001-5009-3960:\n",
      "\n",
      "45958    Taiwan\n",
      "Name: country, dtype: object\n",
      "\n",
      "Group '@path'=/0000-0001-5010-0112:\n",
      "\n",
      "32261    Japan\n",
      "68986    Japan\n",
      "68987    Japan\n",
      "Name: country, dtype: object\n",
      "\n",
      "Group '@path'=/0000-0001-5010-4148:\n",
      "\n",
      "57858    France\n",
      "69517    France\n",
      "83617    France\n",
      "99432    France\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "grouped_data = df.groupby('@path')\n",
    "flag = 0\n",
    "start = 10\n",
    "end = 15\n",
    "# Display the groups\n",
    "for group_name, group_df in grouped_data:\n",
    "    if flag < start:\n",
    "        flag += 1\n",
    "        continue\n",
    "    print(f\"\\nGroup '@path'={group_name}:\\n\")\n",
    "    print(group_df[\"country\"])\n",
    "    flag += 1\n",
    "    if flag > end:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecfa01",
   "metadata": {},
   "source": [
    "At first glance, country migration seems to be relatively rare but definitely happens often enough to be interesting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9724016",
   "metadata": {},
   "source": [
    "### Now lets flatten all of the dataframes into a list of countries, latitudes and longitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0f2df",
   "metadata": {},
   "source": [
    "#### Check out what the grouped data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for null, group_df in grouped_data:\n",
    "    if flag < start:\n",
    "        flag += 1\n",
    "        continue\n",
    "    print(f\"\\nGroup '@path'={group_name}:\\n\")\n",
    "    print(group_df[\"country\"])\n",
    "    flag += 1\n",
    "    if flag > end:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d873a9",
   "metadata": {},
   "source": [
    "#### Aggregate the groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa210149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>@path</th>\n",
       "      <th>country</th>\n",
       "      <th>country_latitude</th>\n",
       "      <th>country_longitude</th>\n",
       "      <th>count</th>\n",
       "      <th>idxs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/0000-0001-5000-0736</td>\n",
       "      <td>[Portugal]</td>\n",
       "      <td>[39.63404977497817]</td>\n",
       "      <td>[-8.055765588295687]</td>\n",
       "      <td>1</td>\n",
       "      <td>[109265]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/0000-0001-5000-5991</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[45.70562800215178]</td>\n",
       "      <td>[-112.5994359115045]</td>\n",
       "      <td>1</td>\n",
       "      <td>[81173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/0000-0001-5002-2708</td>\n",
       "      <td>[United Kingdom, United Kingdom]</td>\n",
       "      <td>[53.91477348053706, 53.91477348053706]</td>\n",
       "      <td>[-2.8531353951805545, -2.8531353951805545]</td>\n",
       "      <td>2</td>\n",
       "      <td>[108768, 128393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/0000-0001-5002-5685</td>\n",
       "      <td>[France, France, France, France]</td>\n",
       "      <td>[42.46070432663372, 42.46070432663372, 42.4607...</td>\n",
       "      <td>[-2.8766966992706267, -2.8766966992706267, -2....</td>\n",
       "      <td>4</td>\n",
       "      <td>[108433, 108434, 127968, 150519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/0000-0001-5002-827X</td>\n",
       "      <td>[South Africa, South Africa]</td>\n",
       "      <td>[-28.947033259979115, -28.947033259979115]</td>\n",
       "      <td>[25.048013879861678, 25.048013879861678]</td>\n",
       "      <td>2</td>\n",
       "      <td>[71238, 119696]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  @path                           country  \\\n",
       "0  /0000-0001-5000-0736                        [Portugal]   \n",
       "1  /0000-0001-5000-5991        [United States of America]   \n",
       "2  /0000-0001-5002-2708  [United Kingdom, United Kingdom]   \n",
       "3  /0000-0001-5002-5685  [France, France, France, France]   \n",
       "4  /0000-0001-5002-827X      [South Africa, South Africa]   \n",
       "\n",
       "                                    country_latitude  \\\n",
       "0                                [39.63404977497817]   \n",
       "1                                [45.70562800215178]   \n",
       "2             [53.91477348053706, 53.91477348053706]   \n",
       "3  [42.46070432663372, 42.46070432663372, 42.4607...   \n",
       "4         [-28.947033259979115, -28.947033259979115]   \n",
       "\n",
       "                                   country_longitude  count  \\\n",
       "0                               [-8.055765588295687]      1   \n",
       "1                               [-112.5994359115045]      1   \n",
       "2         [-2.8531353951805545, -2.8531353951805545]      2   \n",
       "3  [-2.8766966992706267, -2.8766966992706267, -2....      4   \n",
       "4           [25.048013879861678, 25.048013879861678]      2   \n",
       "\n",
       "                               idxs  \n",
       "0                          [109265]  \n",
       "1                           [81173]  \n",
       "2                  [108768, 128393]  \n",
       "3  [108433, 108434, 127968, 150519]  \n",
       "4                   [71238, 119696]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df = grouped_data.agg({'country': list, 'country_latitude': list,'country_longitude': list, 'longitude': 'count', 'latitude': lambda x: x.index.tolist()}).reset_index()\n",
    "result_df = result_df.rename(columns={'longitude': 'count', 'latitude': 'idxs_compatible_with'})\n",
    "display(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a636f",
   "metadata": {},
   "source": [
    "### Define some functions to eliminate duplicates in country, country_latitude, and country_longitude lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18e642ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_duplicates(list_item):\n",
    "    if len(list_item) == 1:\n",
    "        return list_item\n",
    "    building_set = set()\n",
    "    unique_list = [x for x in list_item if not (x in building_set or building_set.add(x))]\n",
    "    return unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0fcc99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elim_dupes_in_row(row):\n",
    "    countries = eliminate_duplicates(row[\"country\"])\n",
    "    country_lats = eliminate_duplicates(row[\"country_latitude\"])\n",
    "    country_longs = eliminate_duplicates(row[\"country_longitude\"])\n",
    "    return (countries,country_lats,country_longs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb514e",
   "metadata": {},
   "source": [
    "### Apply the function to the resultant grouped dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aaf9cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['unique_countries','unique_lats', 'unique_longs']] = result_df.apply(elim_dupes_in_row, axis=1, result_type='expand')\n",
    "display(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1b361",
   "metadata": {},
   "source": [
    "# Convert new dataframe to hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cec4e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3775675/429813720.py:2: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['@path', 'country', 'country_latitude', 'country_longitude', 'idxs',\n",
      "       'unique_countries', 'unique_lats', 'unique_longs'],\n",
      "      dtype='object')]\n",
      "\n",
      "  result_df.to_hdf(output_filename, key='data', mode='w')\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'author_journeys.h5'\n",
    "result_df.to_hdf(output_filename, key='data', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
